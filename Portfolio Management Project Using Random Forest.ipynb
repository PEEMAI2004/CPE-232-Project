{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import MACD, SMAIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project time frame\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2025-05-01\"\n",
    "\n",
    "# Benchmark index\n",
    "benchmark_symbol = \"^GSPC\"\n",
    "\n",
    "# Top 10 symbols from each sector (replace with your actual tickers if needed)\n",
    "sectors = {\n",
    "    \"Technology\": [\"AAPL\"],\n",
    "    # \"Technology\": ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'META', 'TSLA', 'NFLX', 'NVDA', 'INTC', 'AMD'],\n",
    "    # \"Communication\": [\"GOOGL\", \"META\", \"NFLX\", \"TMUS\", \"DIS\", \"VZ\", \"T\", \"CHTR\", \"CMCSA\", \"WBD\"],\n",
    "    # \"Health\": [\"JNJ\", \"PFE\", \"ABBV\", \"LLY\", \"MRK\", \"TMO\", \"BMY\", \"UNH\", \"ABT\", \"CVS\"],\n",
    "    # \"Financials\": [\"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\", \"MS\", \"AXP\", \"USB\", \"BK\", \"SCHW\"],\n",
    "    # \"Defensive\": [\"PG\", \"KO\", \"PEP\", \"WMT\", \"COST\", \"CL\", \"MO\", \"KMB\", \"MDLZ\", \"KR\"],\n",
    "    # \"Cyclical\": [\"AMZN\", \"HD\", \"LOW\", \"MCD\", \"NKE\", \"SBUX\", \"BKNG\", \"TGT\", \"EBAY\", \"GM\"],\n",
    "    # \"Property\": [\"PLD\", \"AMT\", \"CCI\", \"EQIX\", \"DLR\"benchmark_symbol \"SPG\", \"O\", \"PSA\", \"VTR\", \"EXR\"],\n",
    "    # \"Benchmark\": [benchmark_symbol]\n",
    "}\n",
    "\n",
    "# Flatten list of all tickers\n",
    "all_symbols = [symbol for group in sectors.values() for symbol in group]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893f04a",
   "metadata": {},
   "source": [
    "### Load from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from CSV\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"stock_sector_data.csv\"):\n",
    "    stock_df = pd.read_csv(\"stock_sector_data.csv\", parse_dates=[\"Date\"])\n",
    "    print(\"Loaded dataset from CSV.\")\n",
    "else:\n",
    "    print(\"CSV file not found. Please run the download step.\")\n",
    "    \n",
    "# Drop any rows that are not in sectors dictionary\n",
    "stock_df = stock_df[stock_df[\"Symbol\"].isin(all_symbols)]\n",
    "    \n",
    "\n",
    "# Drop any rows with symbol that match the benchmark symbol\n",
    "stock_df = stock_df[stock_df[\"Symbol\"] != benchmark_symbol]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd235b",
   "metadata": {},
   "source": [
    "### Feature Engineering â€” Add Technical Indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(df):\n",
    "    result = []\n",
    "\n",
    "    for symbol in df[\"Symbol\"].unique():\n",
    "        sub = df[df[\"Symbol\"] == symbol].sort_values(\"Date\").copy()\n",
    "\n",
    "        # Momentum: past 1-week and 4-week returns\n",
    "        sub[\"Return_1w\"] = sub[\"Close\"].pct_change(1*7)\n",
    "        sub[\"Return_4w\"] = sub[\"Close\"].pct_change(4*7)\n",
    "\n",
    "        # Volatility: Rolling std dev\n",
    "        sub[\"Volatility_4w\"] = sub[\"Close\"].rolling(window=4*7).std()\n",
    "        \n",
    "        # Moving averages\n",
    "        sub['MA5'] = sub['Close'].rolling(window=5*7).mean()\n",
    "        sub['MA20'] = sub['Close'].rolling(window=20*7).mean()\n",
    "        sub['MA50'] = sub['Close'].rolling(window=50*7).mean()\n",
    "        \n",
    "        # Volume indicators\n",
    "        sub['Volume_Change'] = sub['Volume'].pct_change(periods=7)\n",
    "        sub['Volume_MA5'] = sub['Volume'].rolling(window=5*7).mean()\n",
    "        \n",
    "        # MACD\n",
    "        sub[\"MACD\"] = MACD(close=sub[\"Close\"]).macd()\n",
    "        sub[\"MACD_Signal\"] = MACD(close=sub[\"Close\"]).macd_signal()\n",
    "\n",
    "        # RSI\n",
    "        sub[\"RSI\"] = RSIIndicator(close=sub[\"Close\"], window=14).rsi()\n",
    "\n",
    "        # SMAbenchmark_symbol\n",
    "        # Bollinger Bands\n",
    "        bb = BollingerBands(close=sub[\"Close\"], window=20)\n",
    "        sub[\"BB_Upper\"] = bb.bollinger_hband()\n",
    "        sub[\"BB_Lower\"] = bb.bollinger_lband()\n",
    "        \n",
    "        # \n",
    "\n",
    "        result.append(sub)\n",
    "\n",
    "    features_df = pd.concat(result).reset_index(drop=True)\n",
    "    return features_df\n",
    "\n",
    "features_df = add_technical_indicators(stock_df)\n",
    "features_df = features_df.dropna()\n",
    "features_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf0d67",
   "metadata": {},
   "source": [
    "### Create Outperformance Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6becbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outperformance_labels(features_df, benchmark_df):\n",
    "    # Calculate future return for S&P 500\n",
    "    benchmark_df[\"Benchmark_Return_Next\"] = benchmark_df[\"Close\"].pct_change().shift(-1)\n",
    "\n",
    "    # Ensure 'Date' columns are of the same type\n",
    "    features_df[\"Date\"] = pd.to_datetime(features_df[\"Date\"])\n",
    "    benchmark_df[\"Date\"] = pd.to_datetime(benchmark_df[\"Date\"])\n",
    "\n",
    "    # Merge benchmark return into stock data\n",
    "    df = features_df.merge(benchmark_df[[\"Date\", \"Benchmark_Return_Next\"]], on=\"Date\", how=\"left\")\n",
    "    \n",
    "    # Calculate benchmark return this week\n",
    "    df[\"Benchmark_Return\"] = df[\"Benchmark_Return_Next\"].shift(1)\n",
    "\n",
    "    # Calculate stock return this week and next week\n",
    "    price_col = \"Adj Close\" if \"Adj Close\" in df.columns else \"Close\"\n",
    "    df[\"Stock_Return_Next\"] = df.groupby(\"Symbol\")[price_col].pct_change().shift(-1)\n",
    "    df[\"Stock_Return\"] = df[\"Stock_Return_Next\"].shift(1)\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Calculate this week's pct return over to the benchmark\n",
    "    df[\"Pct_Difference\"] = (df[\"Stock_Return\"] - df[\"Benchmark_Return\"]) / df[\"Benchmark_Return\"]\n",
    "\n",
    "    # Label = 1 if stock outperforms benchmark, else 0\n",
    "    df[\"Label\"] = (df[\"Stock_Return_Next\"] > df[\"Benchmark_Return_Next\"]).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load benchmark data from CSV\n",
    "benchmark_df = pd.read_csv(\"stock_sector_data.csv\", usecols=[\"Date\", \"Symbol\", \"Close\"])\n",
    "benchmark_df = benchmark_df[benchmark_df[\"Symbol\"] == benchmark_symbol].reset_index(drop=True)\n",
    "\n",
    "labeled_df = create_outperformance_labels(features_df, benchmark_df)\n",
    "labeled_df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8aa58",
   "metadata": {},
   "source": [
    "### Train/Test Split & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1231c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Drop rows where the label is missing (NaN due to shifting)\n",
    "    df = df.dropna(subset=[\"Label\"])\n",
    "    \n",
    "    # Fill remaining missing values with median (safe for numeric features)\n",
    "    df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "    # Keep only numeric feature columns\n",
    "    # exclude_cols = ['Date', 'Symbol', 'Sector', 'Label', 'Stock_Return_Next', 'Benchmark_Return_Next']\n",
    "    exclude_cols = ['Date', 'Sector', 'Label', 'Stock_Return_Next', 'Benchmark_Return_Next']\n",
    "    feature_columns = [col for col in df.columns if col not in exclude_cols and df[col].dtype != 'object']\n",
    "    \n",
    "    X = df[feature_columns]\n",
    "    y = df[\"Label\"].astype(int)  # Ensure label is int\n",
    "\n",
    "    # Optional: Scaling (not strictly necessary for Random Forest)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return X_scaled, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dfc3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data: train up to 2023, test after\n",
    "train_data = labeled_df[labeled_df[\"Date\"] < \"2024-11-01\"]\n",
    "test_data = labeled_df[labeled_df[\"Date\"] >= \"2024-11-01\"]\n",
    "\n",
    "X_train, y_train = preprocess_data(train_data)\n",
    "X_test, y_test = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba334e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data\n",
    "print(f\"Training data shape: {X_train.shape}, Labels shape: {y_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}, Labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4165227",
   "metadata": {},
   "source": [
    "### Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation: Metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1c230",
   "metadata": {},
   "source": [
    "### Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351833b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "exclude_cols = ['Date', 'Sector', 'Label', 'Stock_Return_Next', 'Benchmark_Return_Next']\n",
    "\n",
    "# Get feature importances and names\n",
    "feature_columns = [col for col in train_data.columns if col not in exclude_cols and train_data[col].dtype != 'object']\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feat_imp_df, x='Importance', y='Feature')\n",
    "plt.title('Top Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_6_features = feat_imp_df.nlargest(6, 'Importance')['Feature'].tolist()\n",
    "top_6_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b7a11",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix on the training features\n",
    "exclude_cols = ['Date', 'Symbol', 'Sector', 'Label', 'Stock_Return_Next', 'Benchmark_Return_Next']\n",
    "\n",
    "numeric_cols = [col for col in train_data.columns if col not in exclude_cols and train_data[col].dtype != 'object']\n",
    "corr_matrix = train_data[numeric_cols].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bb11e4",
   "metadata": {},
   "source": [
    "### Reduce Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c70d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = top_6_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165cf9d",
   "metadata": {},
   "source": [
    "### Train/Test Split & Preprocessing after Reduce Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7af898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Store the best combination and its score\n",
    "best_combination = None\n",
    "best_score = 0\n",
    "scores = []\n",
    "\n",
    "# Function to evaluate a combination of features\n",
    "def evaluate_combination(combo):\n",
    "    # Preprocess data with the current combination of features\n",
    "    start_time = time.time()\n",
    "    X_train_combo = train_data[list(combo)]\n",
    "    X_test_combo = test_data[list(combo)]\n",
    "\n",
    "    rf_model = RandomForestClassifier(\n",
    "        max_depth=None,\n",
    "        max_features=None,\n",
    "        min_samples_leaf=2,\n",
    "        min_samples_split=2,\n",
    "        n_estimators=500,\n",
    "        bootstrap=False\n",
    "    )\n",
    "    # Train the model\n",
    "    rf_model.fit(X_train_combo, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred_combo = rf_model.predict(X_test_combo)\n",
    "    score = f1_score(y_test, y_pred_combo)\n",
    "    presision = classification_report(y_test, y_pred_combo, output_dict=True)[\"1\"][\"precision\"]\n",
    "    \n",
    "    print(f\"Combination: {combo}, F1 Score: {score}, Precision: {presision}\")\n",
    "    print(f\"Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    return combo, score\n",
    "\n",
    "# Run combinations in parallel\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(evaluate_combination)(combo)\n",
    "    for r in range(1, len(selected_features) + 1)\n",
    "    for combo in combinations(selected_features, r)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b319503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect and rank results\n",
    "scores = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "best_combination, best_score = scores[0]\n",
    "\n",
    "best_combination = np.array(best_combination)\n",
    "\n",
    "print(f\"Best combination: {best_combination}\")\n",
    "print(f\"Best F1 Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3940766",
   "metadata": {},
   "source": [
    "### Apply best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38bfa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the specified hyperparameters and best feature combination\n",
    "rf_model = RandomForestClassifier(\n",
    "    max_depth=None,\n",
    "    max_features=None,\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=100,\n",
    "    bootstrap=False\n",
    ")\n",
    "\n",
    "# exclude_cols = ['Date', 'Symbol', 'Sector', 'Label', 'Stock_Return_Next', 'Benchmark_Return_Next', 'Open', 'High', 'Low']\n",
    "# select_features = [col for col in train_data.columns if col not in exclude_cols and train_data[col].dtype != 'object']\n",
    "\n",
    "# Use the best combination of features\n",
    "select_features = best_combination\n",
    "\n",
    "# Create test and train sets\n",
    "train_data = labeled_df[labeled_df[\"Date\"] < \"2025-01-01\"]\n",
    "test_data = labeled_df[labeled_df[\"Date\"] >= \"2025-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519224f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['Label'].value_counts())\n",
    "print(test_data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ade7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the selected features\n",
    "X_train = train_data[select_features]\n",
    "X_test = test_data[select_features]\n",
    "y_train = train_data[\"Label\"]\n",
    "y_test = test_data[\"Label\"]\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation: Metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa043832",
   "metadata": {},
   "source": [
    "Train with all data except last row of Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66256f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test sets\n",
    "train_data = labeled_df.iloc[:-1]  # All rows except the last one\n",
    "test_data = labeled_df.iloc[-1:]  # Only the last row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['Label'].value_counts())\n",
    "print(test_data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the selected features\n",
    "X_train = train_data[select_features]\n",
    "X_test = test_data[select_features]\n",
    "y_train = train_data[\"Label\"]\n",
    "y_test = test_data[\"Label\"]\n",
    "\n",
    "# Apply the specified hyperparameters and best feature combination\n",
    "big_rf_model = RandomForestClassifier(\n",
    "    max_depth=None,\n",
    "    max_features=None,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=200,\n",
    "    bootstrap=False\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "big_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = big_rf_model.predict(X_test)\n",
    "\n",
    "# Show the prediction\n",
    "print(f\"Predicted label for the last row: {y_pred[0]}\")\n",
    "print(f\"Actual label for the last row: {y_test.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fbbf03",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8668eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [2, 4, 5, 6],\n",
    "    'max_features': [None],\n",
    "    'bootstrap': [False]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb93b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 5),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,  # Number of parameter settings sampled\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af19f1",
   "metadata": {},
   "source": [
    "###  Cross-Validation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da614a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=TimeSeriesSplit(n_splits=5), scoring='f1')\n",
    "\n",
    "# Print the results\n",
    "print(\"Cross-Validation F1 Scores:\", cv_scores)\n",
    "print(\"Mean F1 Score:\", np.mean(cv_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
